\documentclass[11pt,a4paper]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage[top=1in,bottom=1in,left=1in,right=1in]{geometry}
\linespread{2}
\begin{document}
\title{Unsupervised Learning of Images:\\VAE, PixelCNN and VQ-VAE}
\author{Jiang Yu, Fanglin Chen}
\date{Dec 2017}
\maketitle

\section{Introduction}
Recent advances in generative modelling of images have yielded impressive samples and applications. Maximum likelihood and reconstruction error are two common objectives used to train unsupervised models in the pixel domain, however their usefulness depends on the particular application the features are used in.

\section{Models}
\subsection{VAE}
\subsection{VQ-VAE}
\subsection{PixelRNN}
\subsection{PixelCNN}
\subsection{WaveNet}
Audio
\subsection{ByteNet}
Text
\subsection{Summary}

\section{Experiments}
For the CIFAR-10 dataset, the model performances are:\\
\begin{tabular}{lc}
	\hline Model & NLL Test (Train) \\
	\hline PixelRNN & 3.00 (2.93) \\
	\hline PixelCNN & 3.14 (3.08) \\
	\hline Gated PixelCNN & 3.03 (2.90) \\
	\hline VAE & 4.51 \\
	\hline VQ-VAE & 4.67 \\
	\hline 
\end{tabular}

\section{Conclusion}
Please check: 
https://medium.com/intuitionmachine/voice-style-transfer-using-deep-learning-d173f1608af5
\end{document}
